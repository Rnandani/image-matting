A common problem in video analysis is to track a specific object over a period of time. The relationship between this and image matting is immediately apparent, in that both techniques aim to determine which part of an image is a specific object. The key difference is that in image matting, a user must give constraints, whereas in tracking the goal is to automatically determine which part of a frame is the object given only the same knowledge for the previous frames. This issue is overcome in \cite{fan10} by building model of the object being tracked, kicked off by actual user constraints on the first frame. This is then used it to produce a ``user sketch" entirely programmatically at each subsequent frame, before applying the standard image matting algorithm.
\\\\
The model of the object generated is divided into three major components. First, a set of \textbf{salient points} (points recognizable is lying inside the object) are generated. A scribble can be produced by drawing lines between these salient points. However, as an object moves or deforms, these points can quickly become unrecognizable by simple algorithms. As such they are generated as the program goes on, and are a purely short-term part of the model. Next, a set of \textbf{discriminative colors} are selected. These are specific colors which occur far more frequently in either the foreground or the background, and are generally a much better long-term indicator of where a given object lies. However, they are also updated as frames are processed, since new parts of an object might become visible. Finally, the region of the image known to be foreground is cut up into square regions, and each of these regions is stored individually in a \textbf{bag of patches}. At each frame, each patch is checked against the contents of the scene. If some patch is found to be unobscured, it is assumed to be part of the foreground. These patches are the most long-term model of the object, and can be used to determine new salient points even when the tracked object is severely occluded (i.e. something passes in front of it) or deformed.
\\\\
With these three models, each of which is sequentially updated by methods described in \cite{fan10}, a sufficiently accurate and dense user sketch can be generated to apply image matting effectively at each frame. The results far outperform more traditional video matting techniques for tracking.