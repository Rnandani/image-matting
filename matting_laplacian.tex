When dealing with image matting, we can construct a graph such that each pixel is a vertex and adjacent pixels share an edge. Such a graph is naturally undirected and non-looping. However, a large part of image matting is determining appropriate weights for the edges, so we cannot immediately construct a Graph Laplacian. Instead, we use a variant of the Graph Laplacian called the \textbf{Matting Laplacian} \cite{levin08}.
Although identical in construction, our $D$ and $W$ must be produced differently from simple adjacency. The distance between pixels must come into play, but it is weighted by differences in color. For example, two red pixels a slight distance apart would likely be more ``adjacent" than a red and a blue pixel directly next to each other. The number we use is called the \textbf{affinity function}, and many different algorithms exist for its production. We use the affinity function from \cite{levin08}, which is described in \textbf{Techniques}.
\\\\
In general, we can solve for our values of $\alpha$ by minimizing the quadratic form
\[J(\alpha)=\alpha^T L\alpha=\sum_{i,j}W_{ij}(\alpha_i-\alpha_j)^2\]
To develop an intuition for why this works, we consider how this matrix interacts with our values of $\alpha$. Each term of $J(\alpha)$ is an $\alpha_i$ multiplied by a value ($D_i$) roughly approximating how ``connected" it is to other pixels, minus the $\alpha_j$ values for each of the pixels it is connected to, weighted by those connections ($W_{ij}$). This means that the minimal $J(\alpha)$ occurs when strongly connected pixels have very similar alpha values. Remember that this notion of pixel connectedness is a function of both distance and color difference. Then sudden changes in alpha must occur where the color of the image changes rapidly. Since this is generally the case between the borders of objects in an image, minimizing $J(\alpha)$ corresponds to fitting regions of similar $\alpha$ to the objects in the image. Adding in using constraints (the ``sketch") lets us specify which regions should generally be high alpha, and which low.
\\\\
We can minimize our quadratic form to a non-trivial solution by solving a constrained sparse system of linear equations.  To do this, we use Lagrange Multipliers and our sketch.
We suppose that we have some vector of values, $\textbf{g}$, such that the values of $g_i$ are user constraints at each pixel, i.e. 1 where the user has indicated a pixel is in the foregroup, and 0 everywhere else. We then define a diagonal matrix $C$ where $C_ii$ is $1$ if the user has constrained pixel $i$, and $0$ elsewhere. Taking the gradient of our quadratic form, and adding in our sketch, we now have the constrained system of linear equations
\[\nabla J(\alpha)=L\alpha=0,\hspace{.5in}\alpha C=\textbf{g}\]
From Lagrange's method, we can now minimize our quadratic form $J(\alpha)$ by instead solving
\[L\alpha+\gamma\left(\alpha C-\textbf{g}\right) = 0
	\hspace{.2in}\text{ or }\hspace{.2in}
	(L+\gamma C)\alpha = \gamma \textbf{g}\]
so we have our system of linear equations. By picking some large, positive $\gamma$, we can then solve for our desired minimal solution under our constraints. The majority of this paper is devoted to methods for efficiently solving this system of equations for any given Matting Laplacian and sufficient constraints.