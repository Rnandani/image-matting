When dealing with image matting, we can construct a graph such that each pixel is a vertex and adjacent pixels share an edge. Such a graph is naturally undirected and non-looping. However, a large part of image matting is determining appropriate weights for the edges, so we cannot immediately construct a Graph Laplacian. Instead, we use a variant of the Graph Laplacian called the \textbf{Matting Laplacian} \cite{levin08}.
Although identical in purpose, our $D$ and $W$ must be produced differently from simple adjacency. The distance between pixels must come into play, but it is weighted by differences in color. For example, two red pixels a slight distance apart would likely be more ``adjacent" than a red and a blue pixel directly next to each other. The way we produce these numbers is called the \textbf{affinity function}, and it has been defined in many different ways. We use the affinity function from \cite{levin08}, which is described in \textbf{Techniques}.
\\\\
In general, we can solve for our values of $\alpha$ by minimizing the quadratic form
\[J(\alpha)=\alpha^T L\alpha=\sum_{i,j}W_{ij}(\alpha_i-\alpha_j)^2\]
To develop an intuition for why this works, we consider the second of the forms above. The $(\alpha_i-\alpha_j)^2$ term is small in regions with relatively uniform transparency, and large where tranparency shifts suddenly. In contrast $W_{ij}$ term is large where colors change slowly and small where colors change quickly. This means that, if colors are changing slowly, we want the changes in $\alpha$ to be slow as well, or else we'll have large terms add up. Then a good solution to the equation makes regions of similar transparency align roughly with regions of similar color. Since this means that objects (generally of similar color) will be given a roughly fixed alpha, this result is desirable. Note that a trivial solution to this equation is to have every term of $\alpha$ equal. This solution is prevented by our user constraints (the ``sketch"), so that we can instead converge towards some minimal solution that has regions of high $\alpha$ and low $\alpha$ where the user desires.
\\\\
We can minimize our quadratic form to a non-trivial solution by solving a constrained sparse system of linear equations.  To do this, we use Lagrange Multipliers and our sketch.
We suppose that we have some vector of values, $\textbf{g}$, such that the values of $g_i$ are user constraints at each pixel, i.e. 1 where the user has indicated a pixel is in the foreground, and 0 everywhere else. We then define a diagonal matrix $C$ where $C_ii$ is $1$ if the user has constrained pixel $i$, and $0$ elsewhere. Taking the gradient of our quadratic form, and adding in our sketch, we now have the constrained system of linear equations
\[\nabla J(\alpha)=L\alpha=0,\hspace{.5in}\alpha C=\textbf{g}\]
From Lagrange's method, we can now minimize our quadratic form $J(\alpha)$ by instead solving
\[L\alpha+\gamma\left(\alpha C-\textbf{g}\right) = 0
	\hspace{.2in}\text{ or }\hspace{.2in}
	(L+\gamma C)\alpha = \gamma \textbf{g}\]
so we have our system of linear equations. By picking some large, positive $\gamma$, we can then solve for our desired minimal solution under our strict constraints. The majority of this paper is devoted to methods for efficiently solving this system of equations for any given Matting Laplacian and sufficient constraints.